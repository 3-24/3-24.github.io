<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-05-23T21:45:10+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Three Dash Two Four</title><subtitle>수학과 개발을 오가며</subtitle><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><entry><title type="html">쌍을 포함하는 부분구간수열의 개수 세기</title><link href="http://localhost:4000/algorithm/1/" rel="alternate" type="text/html" title="쌍을 포함하는 부분구간수열의 개수 세기" /><published>2021-05-22T00:00:00+09:00</published><updated>2021-05-22T00:00:00+09:00</updated><id>http://localhost:4000/algorithm/1</id><content type="html" xml:base="http://localhost:4000/algorithm/1/">## 문제

0과 1로 이루어진 수열 a가 있다. 이 수열의 부분구간수열을 a의 시작과 마지막부분에서 각각 0개 이상의 원소를 빼서 만들어지는 수열이라고 하자. 이 수열의 각 부분구간수열이 가지는 (1,1)의 쌍의 개수를 구해야 한다.

예를 들어, 수열이 [0, 1, 1, 0, 1]이라면, [1,1], [0, 1, 1], [1, 1, 0], [0, 1, 1, 0], [1, 0, 1]은 1개, [1, 1, 0, 1], [0, 1, 1, 0, 1]은 3개의 (1,1)쌍을 포함하므로, 총 11개이다.

알고리즘의 시간복잡도는 수열의 길이 N에 대해 선형이어야 한다.



## 풀이 1 - 인덱스에 대한 DP

모든 부분구간수열에 대해 (1,1)쌍의 개수를 세려면 부분구간수열의 총 개수가 $O(N^2)$이므로 요구되는 시간에 맞출 수가 없다.

$D_i$를 i번째 인덱스로 끝나는 각 구간에 대해 (1,1) 쌍의 개수의 총합으로 놓자. 그러면

- 0번째 인덱스로 끝나는 구간은 (1,1)을 포함하지 않으므로 $D_0 = 0$

- $ a_{i+1} = 0$인 경우, $D_{i+1}= D_i$.
- $a_{i+1}= 1$인 경우, $D_{i+1} = D_i + (x_1 + 1) + (x_2 + 1) + \cdots$. 이 때 $\{x_1, x_2, \cdots \}$는 $\{a_0, a_1, \cdots, a_{i}\}$에서 값이 1인 원소들의 인덱스이다.

예를 들어 a가 [0, 1, 1, 0, 1]이었다면, $x_1 = 1, x_2 = 2, x_3 = 4$로,

- $D_0 = 0$
- $D_1 = D_0 = 0$
- $D_2 = D_1 + (x_1 + 1) = 2$

- $D_3 = D_2 = 2$
- $D_4 = D_3 + (x_1 + 1) + (x_2 + 1) = 7$

따라서 각 부분구간수열이 가지는 (1,1) 쌍의 개수의 총합은 $D_0 + D_1 + \cdots + D_4 = 11$이다.

이 알고리즘은 $D_{i+1}$을 계산할 때 $a_{i+1} = 0$이면 바로 결과가 나오고, $a_{i+1} = 1$인 경우 $\sum (x_j + 1)$을 계산할 때 **구간 합(prefix sum)**을 이용하면 바로 결과가 나오게 할 수 있다.

```c++
#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long int ll;

int main(){
    int n;                              // 입력의 길이
    cin &gt;&gt; n;
    int val;
    ll D[n+1];							// DP를 누적시킬 배열
    ll psum = 0;
    ll result = 0;
    for (int i=0;i&lt;n;i++){
        cin &gt;&gt; val;
        if (i == 0) D[i] = 0;
        else {
            if (val == 0) D[i] = D[i-1];
            else {
                D[i] = D[i-1] + psum;
                psum += i + 1;
            }
        }
        result += D[i];
    }
    
    cout &lt;&lt; result &lt;&lt; endl;
    return 0;
}
```



## 풀이 2 - 각 (1,1) 쌍에 대해 세기

각 (1,1) 쌍에 대해 그 쌍을 포함하는 부분구간수열의 개수를 세는 방법을 생각해볼 수 있는데, 그것 또한 (1,1) 쌍의 개수가 $O(N^2)$이기 때문에 부족하다

&lt;div align='center'&gt;
    &lt;img src=&quot;https://i.imgur.com/2aiUv2f.png&quot; width=&quot;80%&quot;&gt;
    &lt;figcaption&gt; Figure 1. 각 (1,1)쌍에 대해 그 쌍을 포함하는 구간의 개수 &lt;/figcaption&gt;
&lt;/div&gt;

하지만 Figure 1처럼 (1,1)쌍의 두 번째 1의 인덱스가 같은 것끼리 비교하면 공통점이 보이기 시작한다. 두 번째와 세 번째는 모두 (N-x3)가 곱해지고, 네 번째부터 마지막까지는 (N-x4)가 곱해진다.

두 번째 1의 인덱스를 기준으로 개수를 세면

- 두 번째 1의 인덱스가 x2인 각 (1,1)에 대해 이를 포함하는 구간의 개수는 $(x_1 + 1)(N-x_2)$
- 두 번째 1의 인덱스가 x3인 각 (1,1)에 대해 이를 포함하는 구간의 개수는 $(x_1 +1 + x_2 + 1)(N-x_3)$
- 두 번째 1의 인덱스가 x4인 각 (1,1)에 대해 이를 포함하는 구간의 개수는 $(x_1 +1 + x_2 + 1+x_3+1)(N-x_4)$ 

이런 식으로 마지막 1에 도달할 때까지 계속 반복해서 더해나가면 된다.

각 경우에 대해 $(N-x_i)$는 바로 계산 가능하고, $\sum_{i=1} ^m {x_i} + m$은 **구간 합(prefix sum)**을 이용하면 바로 계산 가능하다.

```c++
#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long int ll;

int main(){
    int n;								// 입력의 길이
    cin &gt;&gt; n;
    int val;
    vector&lt;int&gt; m;						// 1의 인덱스를 저장하는 벡터
    for (int j=0;j&lt;n;j++){
        cin &gt;&gt; val;
        if (val == 1) m.push_back(j);
    }

    ll result = 0;
    ll psum = 0;
    for (auto &amp;it: m){
        result = result + psum * (n-it);
        psum += it+1;
    }
    cout &lt;&lt; result &lt;&lt; endl;
    return 0;
}
```</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="Algorithm" /><category term="algorithm" /><category term="counting" /><category term="prefix sum" /><summary type="html">문제</summary></entry><entry><title type="html">라그랑주 보간법을 이용하는 수치 미분</title><link href="http://localhost:4000/mathematics/numerical%20analysis/2/" rel="alternate" type="text/html" title="라그랑주 보간법을 이용하는 수치 미분" /><published>2021-05-22T00:00:00+09:00</published><updated>2021-05-22T00:00:00+09:00</updated><id>http://localhost:4000/mathematics/numerical%20analysis/2</id><content type="html" xml:base="http://localhost:4000/mathematics/numerical%20analysis/2/">&gt; 함수의 정확한 형태가 주어지지 않고, 몇몇 점들의 함수값들만 알고 있다면 미분을 어떻게 근사할 수 있을까?

이런 문제에 접근하는 근사 방법들을 일컬어 수치 미분Numerical Differentiation이라고 부릅니다.

## 가장 쉬운 근사

가장 간단한 근사로 미분의 정의를 활용해볼 수 있습니다. 함수 $f$의 $x_0$에서의 미분은 다음과 같이 정의됩니다.

$$
f'(x_0) = \lim _{h \to 0 } \frac {f(x_0 + h) - f(x_0)} h
$$

따라서 $ \dfrac {f(x_0 + h) - f(x_0)} h$를 작은 $h$에 대해서 계산할수록 그 값은 $f'(x_0)$에 이론적으로 가까워집니다.

### 수치적 안정성의 문제

하지만 컴퓨터한테 위 근사를 시키면 수를 표현할 때 사용하는 비트 수에 한계가 있어 반올림을 하게 되는데 이 때 발생하는 오차를 반올림 오차round-off-error라고 합니다.

$$
f(x_0 + h) - f(x_0)  =\delta+ cp(f(x_0+h) - f(x_0))
$$

계산할 때 분자 부분의 반올림 오차를 위와 같이 $\delta$로 놓습니다. $cp(expr)$는 식 expr을 컴퓨터가 계산한 결과를 의미합니다.

이제 양변을 h로 나누면 

$$
\frac{f(x_0 + h) - f(x_0)} h  =\frac \delta h+ \frac {cp(f(x_0+h) - f(x_0))} h 
$$

이기 때문에 전체 오차는 $\delta/h$가 됩니다. 따라서, $h$가 0에 가까워질수록 오차 $\delta / h$가 점점 커지고, 결과적으로 수치적 안정성numerical stability이 부족해집니다.



## 넘어가기 전에

라그랑주 보간법Lagrange interpolation은 함수 f를 n개의 점을 지나는 다항식으로 근사할 수 있습니다. 구간 I 위에서 정의된 $f \in C^{n+1} (I)$가 있고  점 $x_0, x_1, \cdots, x_n$에 대해 값 $f(x_0), f(x_1), \cdots, f(x_n)$ 가 알려져 있을 때

$$
f(x) = \sum _{k=0} ^n f(x_k) L_k(x) + \frac {f^{(n+1)}(\xi(x))}{(n+1)!} (x-x_0)\cdots(x-x_n)\\
\text{where } L_k(x) = \prod _{i=0\\i \ne k} ^{n} \frac {x-x_i}{x_k-x_i}
$$

라는 정리가 알려져 있습니다. 이 때, $\xi(x)$는 $I$에 존재하는 값입니다.

## 가장 쉬운 근사의 재해석, Two-Point Formulas

$f \in C^2 [a,b]$일 때 구간 [a,b]위의 $x_0, x_1=x_0 + h$에 대해 라그랑주 보간법 근사를 적용하면 다음과 같습니다.

$$
f(x) = f(x_0) \frac {x-x_0-h}{-h} + f(x_1) \frac {x-x_0} h + \frac {f''(\xi(x))} 2 (x-x_0) (x-x_0 - h)
$$

여기서 한 번 더 미분하면

$$
f'(x) = - \frac {f(x_0)} h + \frac {f(x_1)} h + \frac {(2(x-x_0) - h)} 2 f'' (\xi(x)) + \frac { (x-x_0)(x-x_0-h)} 2 \frac {d}{dx} f''(\xi(x))
$$

가 되고, $x= x_0$를 넣으면

$$
f'(x_0) = \frac { f(x_0 + h) - f(x_0)} h - \frac h 2 f''(\xi(x_0))
$$

를 얻습니다. 이는 처음에 미분 정의로 근사했던 게 점 두개로 라그랑주 보간법을 사용한 결과와 상통합니다. 심지어

$$
\left| f'(x_0) - \frac { f(x_0 + h) - f(x_0)} h  \right| = \left|\frac h 2 f''(\xi(x_0))\right| = \frac {|h|} 2 \max _{a \le x \le b} |f''(x)|
$$

라는 error bound까지 얻을 수 있네요!

이 근사법에서
- h &gt; 0이면 forward-difference formula
- h &lt; 0이면 backward-difference formula

라고 부릅니다.

## (n+1)-Point Formulas

라그랑주 보간법은 여러 개의 점을 통한 근사 방법을 제공하기 때문에 Two-Point Formulas를 넘어서 Three-Point, Four-Point, Five-Point Formulas, ...로 자연스럽게 확장이 가능합니다. 점 $x_0, \cdots, x_n$에 대한 정보가 있을 때 라그랑주 보간법 근사를 적용한 후 양변에 미분한 다음 $x=x_j$를 넣으면

$$
f'(x_j) = \sum_{k=0} ^n f(x_k) L_k ' (x_j) + \frac {f^{(n+1)} (\xi(x_j))}{(n+1)!} \prod _{k=0\\k\ne j}^n (x_j-x_k)
$$

이고, $x_0, \cdots, x_n$이 서로 h씩 균등하게 떨어져 있다면 $(x_j - x_k)$는 h에 비례하는 값이므로, error term이 $O(h^n)$입니다. 즉, 같은 h를 쓰더라도 n이 클수록 더 많은 정보를 미분할 때 사용하였기 때문에 two-point formula보다 점점 정확해집니다.

여기서 주로 사용하는 버전은 three-point와 five-point formula입니다. 여기서는 간단하게 three-point formula만 소개하려 합니다.

### Three-Point Formulas

$x_0, x_1= x_0 + h, x_1 = x_0 + 2h$에 대하여 위에서 구한 결과를 간단한 미분을 통해 정리하면

$$
\begin{aligned}
f'(x_j)
&amp;= f(x_0) \frac {2x_j - 2x_0 - 3h} {2h^2}
- f(x_0 + h) \frac {2x_j - 2x_0 - 2h}{h^2}
\\&amp;+ f(x_0 + 2h) \frac {2x_j - x_0 - h}{2h^2}
+ \frac 1 6 f^{(3)} (\xi_j) \prod _{k=0\\k\ne j } ^2 (x_j - x_k)
\end{aligned}
$$

이고, 결과적으로 다음의 결과를 얻습니다.
- $\displaystyle f'(x_0) = \frac {1} {2h} [-3f(x_0) + 4(x_0+ h) - f(x_0 + 2h)] + \frac {h^2} 3 f^{(3)}(\xi_0)$
- $\displaystyle f'(x_1) = \frac 1 {2h} [-f(x_1-h) + f(x_1 + h)] - \frac {h^2} 6 f^{(3)}(\xi_1)$
- $\displaystyle f'(x_2) = \frac 1 {2h} [f(x_2 - 2h) -4f(x_2 - h) + 3f(x_2)]  + \frac {h^2} 3 f^{(3)}(\xi_1)$

자세히 보면 $x_1$을 넣은 midpoint formula가 error term이 가장 작게 나오고 $f(x_1 + h)$도 사용하지 않아도 되기에 실제 사용에서 가장 선호됩니다. 나머지 두 endpoint formulas는 주어진 데이터셋에서 그 점이 끝점인 특정 경우에서 유용합니다.


## 수치적 안정성

three-point midpoint formula는 다음과 같습니다.

$$
f'(x_0) = \frac 1 {2h} [f(x_0 + h)-f(x_0-h)] - \frac {h^2} 6 f^{(3)}(\xi) \quad \text{ where } h &gt; 0
$$

이 때 각 함수값의 round-off error를 $\epsilon$으로, 다음과 같이 정의해볼 수 있습니다.

$$
\epsilon = \max \{|f(x_0 + h) - cp(f(x_0 + h))|, |f(x_0-h) - cp(f(x_0 - h))| \}
$$

그러면

$$
\begin{aligned}
e(h) &amp;= \left|f'(x_0) - \frac {1}{2h} [cp(f(x_0 + h)) - cp(f(x_0 - h))]\right|
\\ &amp;= \left | \frac 1 {2h} [f(x_0 + h)-f(x_0-h)] - \frac {h^2} 6 f^{(3)}(\xi) - \frac {1}{2h} [cp(f(x_0 + h)) - cp(f(x_0 - h))] \right|
\\ &amp;\le \frac {h^2} 6 M + \frac \epsilon h\quad \text{ where } M = \max_{x \in I} {|f^{(3)}(x)|}
\end{aligned}
$$

전항 $h^2M / 6$은 원래 구했던 오차(truncation error이고, $\epsilon / h$는 round-off error로 인해 발생한 새로운 항입니다. h가 작을수록 truncation error는 작아지지만, round-off error는 커지는 상황이에요. 처음에 다루었던 가장 쉬운 근사에서도 겪었던 문제입니다.
&gt; truncation error과 round-off error 사이의 tradeoff

이를 최소화하는 선택은 $e(h)$를 최소화하는 문제로, 미분하고 0이 되는 점을 찾아서 구해보면 $h = \sqrt[3]{3\epsilon / M}$이 가장 오차가 작습니다. 실제로는 $M$을 구하는 게 미분을 근사하는 것보다 훨씬 어려운 문제이니 뚜렷한 답은 없습니다. 그냥 $h$를 무조건 작게 잡는게 능사는 아니라는 것 뿐..

## Second Derivative Midpoint Formula

마지막으로 이계 미분을 근사하는 기법에 대해서 소개하고 마치려 합니다. 3차 테일러 근사를 이용하면

$$
f(x_0 + h) = f(x_0) + f'(x_0) h + \frac 1 2 f''(x_0) h^2 + \frac 1 6 f'''(x_0) h^3 + \frac 1 {24} f^{(4)}(\xi_1)h^4\\
f(x_0 - h) = f(x_0) - f'(x_0) h + \frac 1 2 f''(x_0) h^2 - \frac 1 6 f'''(x_0) h^3 + \frac 1 {24} f^{(4)}(\xi_{-1})h^4\\
\text{where } x_0 - h &lt; \xi_{-1} &lt; x_0 &lt; \xi &lt; x_0 + h
$$

이고, 이 둘을 더하면 $f'(x_0)$가 포함된 항은 소거되어서

$$
f''(x_0) = \frac 1 {h^2} [f(x_0-h) - 2f(x_0) + f(x_0 + h)] - \frac {h^2} {24} [f^{(4)}(\xi_1) + f^{(4)}(\xi_{-1})]
$$

인데, intermediate value theorem에 의하여

$$
f''(x_0) = \frac 1 {h^2} [f(x_0-h) - 2f(x_0) + f(x_0 + h)] - \frac {h^2}{12} f^{(4)}(\xi)
$$

가 도출됩니다. 이렇게 $f \in C^4[x_0-h, x_0+h]$일 때 오차가 $O(h^2)$인 $f \prime\prime (x_0)$에 대한 근사를 얻었습니다.

## References

[1] KAIST 2021 Spring MAS365 Numerical Analysis</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="Mathematics" /><category term="Numerical Analysis" /><category term="differentiation" /><summary type="html">함수의 정확한 형태가 주어지지 않고, 몇몇 점들의 함수값들만 알고 있다면 미분을 어떻게 근사할 수 있을까?</summary></entry><entry><title type="html">Jekyll - 올바른 RSS가 아닙니다 (네이버 서치어드바이저)</title><link href="http://localhost:4000/scribbles/naver-search-atom/" rel="alternate" type="text/html" title="Jekyll - 올바른 RSS가 아닙니다 (네이버 서치어드바이저)" /><published>2020-12-03T00:00:00+09:00</published><updated>2020-12-03T00:00:00+09:00</updated><id>http://localhost:4000/scribbles/naver-search-atom</id><content type="html" xml:base="http://localhost:4000/scribbles/naver-search-atom/">블로그의 유입을 늘리려고 이 블로그를 네이버 서치어드바이저에 검색 등록을 하다가 [https://3-24.github.io/feed.xml](https://3-24.github.io/feed.xml)의 RSS 제출에서 올바르지 않은 RSS라고 거부당했는데 원인을 알려주지 않아서 꽤 당혹스러웠습니다.

&lt;div align='center'&gt;
    &lt;img src=&quot;/assets/img/search_error.png&quot;&gt;
    &lt;figcaption&gt; Figure 1. 오류 창 &lt;/figcaption&gt;
&lt;/div&gt;

조사해보니까 피드 파일을 생성하는 jekyll-feed 플러그인이 Atom 문법으로 feed.xml 파일을 생성하는데, 서치 어드바이저는 RSS를 요구해서 생기는 문제였습니다. Atom은 RSS보다 가지는 이점이 몇 개 존재하는 더 진보된 양식이고, 점점 Atom의 점유율이 높아지는 추세이긴 합니다만, 네이버에서 아직 지원을 하지 않는 것 같습니다. 그래서 [Jekyll Codex에 나온 RSS 피드를 수동으로 만든 방법](https://jekyllcodex.org/without-plugin/rss-feed/#)에서 feed.xml 파일 이름만 rss.xml로 살짝 바꿔서 두 가지 피드를 제공하기로 했습니다.

- [https://3-24.github.io/feed.xml](https://3-24.github.io/feed.xml])은 정식으로 사용하는 Atom 피드

- [https://3-24.github.io/rss.xml](https://3-24.github.io/rss.xml)은 RSS 피드

빌드 시간이 더 오래걸리겠지만 검색엔진 등록을 위해서는 어쩔 수 없는 것 같습니다.</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="Scribbles" /><summary type="html">블로그의 유입을 늘리려고 이 블로그를 네이버 서치어드바이저에 검색 등록을 하다가 https://3-24.github.io/feed.xml의 RSS 제출에서 올바르지 않은 RSS라고 거부당했는데 원인을 알려주지 않아서 꽤 당혹스러웠습니다.</summary></entry><entry><title type="html">x86-64 시스템의 i386 아키텍처 호환에 관한 고찰</title><link href="http://localhost:4000/system/arch-elf-study/" rel="alternate" type="text/html" title="x86-64 시스템의 i386 아키텍처 호환에 관한 고찰" /><published>2020-12-01T00:00:00+09:00</published><updated>2020-12-01T00:00:00+09:00</updated><id>http://localhost:4000/system/arch-elf-study</id><content type="html" xml:base="http://localhost:4000/system/arch-elf-study/">&gt; 이 글은 리눅스에서 바이너리와 호환 아키텍처에 관해 찾아보면서 알게 된 것들을 정리한 글입니다. 오류가 있을 수도 있으니 만약에 있다면 너그럽게 알려주시길 바랍니다.

가끔 오래된 바이너리를 보면 별도의 설정 없이 실행을 할 때 다음과 같이 오류를 출력한다. 분명 존재하는 파일인데 왜 없다고 뜨는걸까.

```
$ ./bof
bash: ./bof: No such file or directory
$ file ./bof
bof: ELF 32-bit LSB shared object, Intel 80386, version 1 (SYSV), dynamically linked, interpreter /lib/ld-linux.so.2, for GNU/Linux 2.6.24, BuildID[sha1]=ed643dfe8d026b7238d3033b0d0bcc499504f273, not stripped
```

그래서 file 명령어로 확인해보면 32비트 바이너리라고 하는데, 왜 실행이 안되나 하고 찾아봤더니 [해당 답변](https://askubuntu.com/questions/454253/how-to-run-32-bit-app-in-ubuntu-64-bit)에서는 i386 아키텍처와 관련된 libc 라이브러리를 설치하라고 한다:

```bash
sudo dpkg --add-architecture i386
sudo apt-get update
sudo apt-get install libc6:i386 libncurses5:i386 libstdc++6:i386
```

물론 문제는 해결이 되지만, 아키텍처의 개념과, i386의 의미, 그리고 바이너리가 왜 실행이 안되었는지에 관해 의문이 남아서 열심히 공부하면서 찾아보았다.

'컴퓨터 아키텍처'란 흔히 기계어라고 불리는 명령어 집합(Itruction Set Assembly)에 이를 회로로 구현하는데 사용하는 마이크로아키텍처와 하드웨어 구성을 의미한다. 그리고 x86은 인텔이 개발한 CPU 시리즈와 명령어 집합을 통칭하는 말로, 이름이 x86인 이유는 초기 프로세서들 이름이 8086, 80186, 80286 등 다 86으로 끝나서였다고 한다. 그 중에서도 처음으로 32비트를 지원하는 CPU가 인텔 i386인데, 후에 인텔의 32비트 CPU 컴퓨터 아키텍처 IA-32는 다 이 i386을 기준으로 만들어졌기 때문에 i386 아키텍처는 IA-32를 통칭한다고 볼 수도 있는 것 같다.

하지만 32비트는 메모리 주소를 32비트밖에 사용할 수 없으므로, $2^{32}$바이트, 즉 4기가바이트의 메모리까지만 접근이 가능하다는 한계가 있었고, 더 나아가기 위해 64비트 CPU를 개발하기 위해 IA-32의 확장이 여러 개 제안되었다. 이 중 인텔이 완전히 새롭게 설계하여 IA-32와 호환되지 않는 IA-64와, IA-32와 호환되면서 64비트 명령을 추가한 AMD의 x86-64(또는 AMD64)가 있었다. x86-64가 시장의 선택을 받았고, 이후 인텔도 x86-64를 AMD로부터 라이선스를 받아 구현하면서 IA-64는 사실상 사장되고 x86-64가 표준이 되었다고 한다.

일단 내가 사용하는 리눅스 시스템의 아키텍처는 다음과 같이 x86-64로 확인되었다.

```
$ uname -p
x86_64
```

x86-64 CPU로 i386 프로그램을 실행할 수 있는데 왜 실행이 되지 않는가.. 좀 더 찾아보니 elf 헤더를 읽어보면 다음과 같은 정보가 있다고 한다.

```
$ readelf -a ./bof
ELF Header:
  Magic:   7f 45 4c 46 01 01 01 00 00 00 00 00 00 00 00 00
  Class:                             ELF32
  Data:                              2's complement, little endian
  Version:                           1 (current)
  OS/ABI:                            UNIX - System V
  ABI Version:                       0
  Type:                              DYN (Shared object file)
  Machine:                           Intel 80386
  Version:                           0x1
  Entry point address:               0x530
  Start of program headers:          52 (bytes into file)
  Start of section headers:          4428 (bytes into file)
  Flags:                             0x0
  Size of this header:               52 (bytes)
  Size of program headers:           32 (bytes)
  Number of program headers:         9
  Size of section headers:           40 (bytes)
  Number of section headers:         30
  Section header string table index: 27
 ...
```

즉 Machine이 Intel 80386, 즉 i386을 가리키고, 또한 해당 프로그램이 요구하는 라이브러리를 살펴보면,

```
$ ldd ./bof
linux-gate.so.1 (0xf7f65000)
libc.so.6 =&gt; /lib/i386-linux-gnu/libc.so.6 (0xf7d60000)
/lib/ld-linux.so.2 (0xf7f67000)
```

역시 i386-linux-gnu 하위의 libc 라이브러리가 필요하다. 따라서 저 라이브러리를 dpkg로 설치하기 위해서 apt 패키지 저장소에서 libc를 설치해줘야 했던 것이다.

```
sudo apt-get install libc6:i386
```

를 실행해줘야 한다. 하지만 이를 하기 위해서는 패키지 저장소에 있는 i386 패키지 목록을 받아와야 하므로, 사용하는 아키텍처에 i386을 추가한 다음 apt update를 해줘야 한다. 그리고 이가 가능한 이유는 x86-64가 i386의 명령어 집합을 처리하기 때문이다. 만약 ARM 아키텍처가 요구되는 프로그램이었다면 별도의 에뮬레이터 없이는 실행이 불가능했을 것이다.

정리하자면, 해당 바이너리는 i386 CPU를 요구하는데, x86-64 아키텍처는 커널과 라이브러리의 도움을 받아 i386 바이너리를 실행할 수도 있다. 이를 가능하게 해주는 것이 dpkg을 i386 아키텍처를 추가하여 libc 라이브러리를 설치하게 해주는 것이다. 아직 ELF 프로그램이 실행되는 구체적인 과정 등 완전히 의문이 해소된 것은 아니지만, 이 정도면 그럭저럭 만족할만한 설명을 얻은 것 같다.

## 참고 문서

[1] [IA-32, Wikipedia](https://ko.wikipedia.org/wiki/%EB%AA%85%EB%A0%B9%EC%96%B4_%EC%A7%91%ED%95%A9)

[2] [명령어 집합, Wikipedia](https://ko.wikipedia.org/wiki/%EB%AA%85%EB%A0%B9%EC%96%B4%EC%A7%91%ED%95%A9)

[3] [x86, Wikipedia](https://ko.wikipedia.org/wiki/X86)

[4] [x86-64, Wikipedia](https://ko.wikipedia.org/wiki/X86-64)

[5] [Multiarch, HOWTO - Debian Wiki](https://wiki.debian.org/Multiarch/HOWTO)</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="System" /><category term="Architecture" /><category term="x86_64" /><category term="i386" /><summary type="html">이 글은 리눅스에서 바이너리와 호환 아키텍처에 관해 찾아보면서 알게 된 것들을 정리한 글입니다. 오류가 있을 수도 있으니 만약에 있다면 너그럽게 알려주시길 바랍니다.</summary></entry><entry><title type="html">2020년 여름학기 몰입캠프 후기</title><link href="http://localhost:4000/scribbles/madcamp-review/" rel="alternate" type="text/html" title="2020년 여름학기 몰입캠프 후기" /><published>2020-08-08T00:00:00+09:00</published><updated>2020-08-08T00:00:00+09:00</updated><id>http://localhost:4000/scribbles/madcamp-review</id><content type="html" xml:base="http://localhost:4000/scribbles/madcamp-review/">봄학기 종강을 하자마자 카이스트에서 여름학기로 열리는 몰입캠프에 참여했기 때문에 한동안 정말 바빴다. 어제 몰입캠프 종강을 한 지금, 이 캠프에 참여하면서 얻은 것들을 정리해보고자 한다. 이 후기를 쓰고 있는 나는 카이스트 전산학부지만, 타대생과 컴공이 아닌 다른 전공을 하고 있는 수강생도 많이 볼 수 있었다.



## 개요

- [몰입캠프 메인페이지](https://madcamp.io/)
- [2020년 여름학기 몰입캠프 강의계획서](https://docs.google.com/document/d/1flSaJ4kGRzkpxTTlRNqA7bOC0oI7idQR3PXPnMt9b-g/edit)

실라버스를 보면 알 수 있듯, 완전히 개발 프로젝트 중심의 수업이다. 4주동안 각 주마다 프로젝트 하나를 2~3인 팀을 구성하여 진행하게 된다. 매 주 프로젝트 발표를 마친 후 투표를 하여 금주의 픽으로 선택되면 전체 수강생들 앞에서 한 번 더 발표를 하게 되는 영광을 누릴 수 있다. 금주의 픽 발표가 끝나면 스타트업 관계자가 들려주는 생생한 창업 스토리나 프로젝트에 사용될만한 기술, 개발 방법론 등을 들을 수 있다.



## 프로젝트

프로젝트를 위해 20명으로 구성된 각 반마다 실습실 하나를 사용하게 된다. 인당 모니터 두 대와 쓸만한 성능의 컴퓨터를 사용하게 된다.

이 수업을 듣기 전에 나는 개발 중에 사용한 대부분의 프로그래밍 언어나 프레임워크로 개발한 경험은 없지만, CTF 문제를 풀어보면서 기본적인 서버와 데이터베이스 개념과 몇 가지 문법을 이용해본 적이 있는 정도였다. 그래서 사용하는 기술에 대한 적응은 빠른 편이었던 것 같다. 혼자서는 한 주 만에 절대 하지 못했을 것 같지만 주변에 물어볼 사람도 많고 다 같이 몰입하며 열심히 하는 분위기가 형성되기 때문에 나도 놀랄 정도로 많은 기술들을 공부하고 적용해볼 수 있었다.

각 프로젝트에서 세부적으로 했던 일들은 다음과 같다. 자랑할만 하지는 않지만 프로젝트 소스코드도 같이 올려놓았다.

### 1주차

- [영석이의 하루 Github](https://github.com/3-24/madcamp1)

안드로이드 앱 개발을 한다. 탭1에는 사용자의 연락처 목록을 받아와 연락처 화면을 구성하고, 탭2에는 사진을 받아와서 갤러리 화면을 구성한다. 마지막 탭3은 자유 주제로, 나는 날씨 API에서 현재 위치하고 있는 지역의 날씨 정보를 받아와 일기예보를 보여주는 화면을 만들었다. 사용하는 언어나 프레임워크는 자유이고, 나를 포함한 대부분의 사람들은 기본 안드로이드 자바 프로그래밍을 하였다.

### 2주차

- [밤편지 프런트엔드 Github](https://github.com/3-24/madcamp2)

- [밤편지 백엔드 Github](https://github.com/3-24/madcamp2_backend)

안드로이드 앱 개발은 그대로이지만, 서버와 데이트베이스 기술을 적용해야 한다. 탭1과 탭2의 형식은 연락처와 갤러리로 동일하나 서버와 상호작용하는 부분을 추가해야 한다. 나는 1주차 때 했던 탭1 탭2 구성을 똑같이 하고 싶지 않아서 간단한 SNS 서비스를 만들어 탭1을 친구 목록, 탭2를 피드로 대체하였다. 새로운 개발 프레임워크를 경험하고 싶어서 React Native를 이용해보았고, 백엔드 서버는 NodeJS와 MySQL 데이터베이스를 사용하였다.

### 3주차

- [고양이가세계를지배한다냥 프런트엔드 Github](https://github.com/CatDominatesWorld/CatDominatesWorld)
- [고양이가세계를지배한다냥 백엔드 Github](https://github.com/CatDominatesWorld/CatDominatesWorld-backend)

&lt;div align='center'&gt;
    &lt;img src=&quot;https://github.com/CatDominatesWorld/CatDominatesWorld/blob/master/asset/demo.png?raw=true&quot; width=&quot;90%&quot;&gt;
    &lt;figcaption&gt; Figure 1. 위키피디아 COVID-19 문서에 적용한 모습 &lt;/figcaption&gt;
&lt;/div&gt;

**자유 주제**. 나는 웹 페이지에 표시되는 모든 텍스트를 '냥'과 'meow'로 바꾸고, 모든 사진에서 얼굴을 인식하면 고양이 얼굴로 바꾸는 크롬 익스텐션을 만드는 프로젝트를 하였다. 크롬 익스텐션 쪽은 HTML/CSS와 Javascript를 이용하여, 그리고 자연어 처리와 얼굴 인식을 하여 변환 부분을 담당하는 백엔드 서버는 Python 3기반으로, 통신은 Flask, 이미지 프로세싱은 OpenCV, 자연어 처리는 konlpy와 nltk 라이브러리, 얼굴 인식은 카카오 Vision API를 사용하였다.

### 4주차

**자유 주제**. Unreal Engine을 이용해 3차원 잠입 액션 게임을 만들었다. 언리얼 엔진은 애니메이션 하나만 추가해도 150MB만큼의 용량을 요구하기 때문에(...) Github를 통해 관리하다가 포기했다.

&lt;div align='center'&gt;
    &lt;img src=&quot;/assets/img/phantom_sight.png&quot; width=&quot;90%&quot;&gt;
    &lt;figcaption&gt; Figure 2. Phantom Sight - 3차원 잠입 액션 게임 &lt;/figcaption&gt;
&lt;/div&gt;



## 마치며

한 달 동안 같은 실습실에서 밤을 새면서 개발을 하기 때문에 다 같이 친해지게 된다. 식사나 술자리를 자주 가졌고, 심지어 엠티를 다녀오기도 했다. 정말 착하고 좋은 다양한 사람들을 만나서 4주 내내 행복했다. 신청을 할 때를 돌이켜 생각해보면 정말 여러가지 동기가 복합적으로 작용했었다.

- 여러 명이 참여하는 개발 프로젝트를 경험하고, 개발 역량을 키우기 위해서
- 방학을 의미있게 보내고 싶어서
- 개발에 관심이 있는 새로운 사람을 만나고 싶어서
- 스타트업 생태계에 대한 생생한 정보를 듣고 싶어서

결과적으로 내가 기대했던 것들을 다 얻을 수 있었고, 정말 잊지 못할 방학이 될 것 같다. COVID-19로 어려움이 있음에도 불구하고 이런 기회를 준 교수님들, 강연자분들과 같은 공간에서 같이 밤을 샌 반 동료들에게 감사한다.</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="Scribbles" /><category term="madcamp" /><summary type="html">봄학기 종강을 하자마자 카이스트에서 여름학기로 열리는 몰입캠프에 참여했기 때문에 한동안 정말 바빴다. 어제 몰입캠프 종강을 한 지금, 이 캠프에 참여하면서 얻은 것들을 정리해보고자 한다. 이 후기를 쓰고 있는 나는 카이스트 전산학부지만, 타대생과 컴공이 아닌 다른 전공을 하고 있는 수강생도 많이 볼 수 있었다.</summary></entry><entry><title type="html">단일프로세서 스케줄링</title><link href="http://localhost:4000/system/scheduler-policy/" rel="alternate" type="text/html" title="단일프로세서 스케줄링" /><published>2020-06-20T00:00:00+09:00</published><updated>2020-06-20T00:00:00+09:00</updated><id>http://localhost:4000/system/scheduler-policy</id><content type="html" xml:base="http://localhost:4000/system/scheduler-policy/">사용할 수 있는 CPU는 유한하지만 운영체제는 여러 개의 일task를 한꺼번에 작동시켜야 한다. 그래서 운영체제에서 일이 CPU를 점유하는 시간을 관리해주는 부분이 필요한데, 이를 스케줄러scheduler라고 한다.



## Performace Metric

어떤 방식의 스케줄링을 사용하는 것을 고민하기 전에, 그 스케줄링이 얼마나 효율적인지를 나타내는 지표들을 정리해보았다.

1. throughput: 시간당 처리가 끝나는 일의 수
2. turnaround time: 일이 완전히 처리될 때까지 걸리는 시간 ($T_{fin} - T_{arrival}$)
3. response time: 일이 처음 반응하기까지 걸리는 시간 ($T_{response} - T_{arrival}$)
4. waiting time: ready, wait상태에서 일이 기다린 시간의 합

특정 스케줄러로 여러 일을 처리했을 때 위 네 지표가 낮다면 그것은 효율적인 스케줄러이다.



문제의 단순화를 위해 프로세서가 하나만 있는 경우에 대해서만 다룬다.

## 1. FIFO

&gt; 먼저 오는 일을 먼저 처리한다.

가장 먼저 생각해볼만한 방법이다. 먼저 오는 일을 먼저 처리한다. (First-In-First-Out)

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;/assets/img/scheduler/scheduler01.png&quot; width=&quot;90%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 1. FIFO Scheduling
    &lt;/p&gt;
&lt;/div&gt;

하지만 시간이 오래 걸리는 일이 먼저 처리되고, 시간이 적게 걸리는 일에 나중에 처리되면 성능이 급격히 하락한다. 예를 들면 P1, P2, P3, P4가 시간이 각각 20, 4, 3, 3만큼 거리는 일이라고 하고, 이들이 시간 0에 P1, P2, P3, P4 순서대로 FIFO 스케줄러에 도달했다고 하자. 그러면 Figure 1과 같이 스케줄링될 것이다. 그러면 총 turnaround time=20+24+27+30=91, 총 response time=0+20+24+27=71, 총 waiting time=0+20+24+27=71이다.

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;/assets/img/scheduler/scheduler02.png&quot; width=&quot;90%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 2. Optimal Scheduling
    &lt;/p&gt;
&lt;/div&gt;

만약에 Figure 2와 같이 스케줄링되었다면 총 turnaround time=3+6+10+30=49, 총 response time=0+3+6+10=19, 총 waiting time=0+3+6+10=19가 된다. 이와 같이 FIFO 방식으로 스케줄링 했을 때 오래 걸리는 일이 나머지 일의 처리를 지연시키는 상황을 convoy effect라고 한다.



**장점**

* 스케줄러의 계산량이 적다. 이전 일의 처리가 끝날 때마다 ready queue에서 첫 번째 일을 running state로 보내버리면 된다.
* 같은 이유로 구현이 간단하다.

**단점**

* 성능이 나쁘다. convoy effect에 의해 평균 response time, 평균 turnaround time, 평균 waiting time 모두 높다.



## 2. Shortest Job First (SJF)

&gt; 남은 시간이 가장 짧은 일을 먼저 처리한다.

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;/assets/img/scheduler/scheduler02.png&quot; width=&quot;90%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 2. SJF Scheduling (Recall)
    &lt;/p&gt;
&lt;/div&gt;


Figure 2와 같이, **남은 시간이 가장 짧은 일을 먼저 처리하는 방식**이다. 가능한 스케줄링 방식 중에 평균 waiting time이 가장 낮다. 하지만 언제나 시간이 적게 걸리는 일을 시간이 많이 걸리는 일보다 먼저 처리하기 때문에, 시간이 적게 걸리는 일이 계속 쿼리될 경우 시간이 많이 걸리는 일이 먼저 쿼리되었음에도 불구하고 계속 처리가 지연된다. 이런 현상을 **starvation**이라고 한다.

**장점**

- 지표 상 성능이 좋다. 최소의 평균 waiting time을 보장하고, 평균 response time, 평균 turnaround time 모두 빠른 편에 속한다.

**단점**

- starvation이 발생한다.
- 완벽한 구현이 불가능하다. 일반적으로 스케줄러가 특정 일을 처리하기 전에 그 일이 얼마나 걸리는 지 확인할 방법이 없다. 그래서 그 일이 얼마나 걸릴지 이전 일들이 걸린 시간을 통해 유추하는 방법을 사용한다. 스케줄링은 운영체제에서 자주 일어나는 일이기 때문에 높은 계산량을 요구하는 유추 알고리즘은 사용할 수 없고, 이전 일들이 걸린 시간들의 단순한 선형 관계 정도의 유추 전략이 사용된다.



### Starvation을 해결하는 방법

SJF 스케줄링은 남은 시간을 priority(우선도)로 적용한 스케줄링 방식이다. 일반적으로 priority scheduling에서는 priority가 낮은 일이 priority가 높은 일에 비해 우선순위가 밀려서 처리되지 않는 starvation이 발생하는 것이 문제가 된다. 그래서 starvation을 해결하기 위해 다음 기법을 사용한다.

&gt; **Aging**: 프로세스가 오랫동안 기다릴수록 priority를 높인다.

이렇게 starvation 문제를 해결하더라도 SJF는 어디까지나 '이론적인 스케줄러'일 뿐이다.



## 3. Round Robin

&gt; 각 일이 정해진 시간 동안만 실행되는 FIFO

**FIFO지만, 각 일이 특정 시간 동안만 CPU를 점유할 수 있는** 스케줄링 방식이다. 

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;/assets/img/scheduler/scheduler03.png&quot; width=&quot;90%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 3. Round Robin Scheduling
    &lt;/p&gt;
&lt;/div&gt;

Figure 3는 time slice가 2로 설정되었을 때 스케줄링이 어떤 방식으로 이루어지는지를 보여준다. SJF와 달리 starvation도 발생하지 않고, FIFO에서 발생하는 convoy effect도 발생하지 않는다. 이렇게 보기에는 쓸만한 스케줄러 같지만, time slice의 크기에 따라 문제가 발생한다.

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;/assets/img/scheduler/scheduler04.png&quot; width=&quot;90%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 4. Too Short Time Slice
    &lt;/p&gt;
&lt;/div&gt;

time slice가 너무 짧아서 FIFO에 비해 response time은 짧지만 나머지 지표가 좋지 않다. Figure 4에서 Round Robin의 모든 프로세스가 FIFO의 모든 프로세스보다 늦거나 같게 끝난다는 것을 확인할 수 있다.

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;/assets/img/scheduler/scheduler05.png&quot; width=&quot;80%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 5. Too Long Time Slice
    &lt;/p&gt;
&lt;/div&gt;

한편, time slice가 너무 길면 Figure 5와 같이 I/O에 늦게 반응하게 된다. 정리해보면 다음과 같다.

- task가 대부분 CPU의 처리로 이루어진 CPU-bound task라면 time slice가 길어질수록 효율이 좋다. Figure 4에서 논한 문제는 time slice가 짧아서 발생하였다.
- task가 대부분 I/O를 기다리는 I/O-bound task라면 time-slice가 짧아야 한다. 만약 time slice가 길다면 입력과 출력에 반응하는 시간이 오래 걸린다. (response time 중시)

**장점**

- 기본적으로 FIFO이기 때문에 starvation이 발생하지 않는다.

**단점**

* time slice의 설정 방법에 따라, 그리고 스케줄링되는 task의 속성에 따라 성능이 달라진다. 



## 돌아보기

지금까지 FIFO, SJF, Round Robin 스케줄링을 알아보았다. 그 과정에서 각자 발생하는 장점과 단점이 있었는데 이들을 모아서 이상적인 스케줄러의 특성을 나열하면 다음과 같다.

- SJF처럼 짧게 걸리는 일을 빨리 처리해야한다.
- 특정 task가 오랫동안 실행되지 않는 starvation이 발생해서는 안된다.
- 스케줄링을 하는데 걸리는 시간이 오래걸려서는 안된다.
- CPU-bound task에 대해서 turnaround time을 줄여야 하고, I/O-bound task에 대해서 response time을 줄여야 한다.



## 4. Multi-Level Feedback Queue (MFQ)

최종적으로 이 글에서 소개할, 가장 발전된 형태의 uniprocessor 스케줄링 방식이다.

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;/assets/img/scheduler/scheduler06.png&quot; width=&quot;60%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 6. MFQ Scheduling
    &lt;/p&gt;
&lt;/div&gt;


각자 독립된 priority를 가진 round robin 큐를 만든다. 높은 priority를 가진 큐를 rounb robin 방식으로 스케줄링하고, 종료되지 않은 프로세스를 한 단계 낮은 priority를 가진 큐에 넣는다.

- SJF 처럼 짧게 걸리는 일이 빨리 처리되는가? 예

  오래 걸리는 일은 round robin 큐를 여러 개 거치면서 priority가 낮아지기 때문에 짧게 걸리는 일이 우선적으로 처리된다.

- starvation이 발생하지 않는가? 아니오 -&gt; 예(해결 가능)

  스케줄러가 높은 priority의 큐를 우선적으로 처리하기 때문에 낮은 priority의 큐에 있는 일이 오랫동안 처리되지 않는 starvation이 발생할 우려가 있다. 이 문제는 aging을 이용하면 해결된다. 매번 기다리는 상태에 있는 task를 한 단계 더 높은 priority를 가지는 큐에 넣어주면 된다.

- 스케줄링을 하는데 많은 양의 계산을 요구하지 않는가? 예

- CPU-bound task의 turnaround time이 적은가? 아니요-&gt;예(해결 가능)

  priority가 낮아질수록 round robin의 time slice를 높이면 된다.

- I/O-bound task의 reponse가 빠른가? 예

  만약 많은 양의 CPU의 처리가 요구되는 CPU-bound task가 들어온다면, 여러 큐를 거쳐가면서 priority가 낮아지는 반면, I/O-bound task의 경우 프로세서에서 처리하는 시간이 적어 priority가 잘 낮아지지 않기 때문에 높은 priority에 머무른다.</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="System" /><category term="scheduler" /><category term="FIFO" /><category term="SJF" /><category term="round robin" /><category term="MFQ" /><summary type="html">사용할 수 있는 CPU는 유한하지만 운영체제는 여러 개의 일task를 한꺼번에 작동시켜야 한다. 그래서 운영체제에서 일이 CPU를 점유하는 시간을 관리해주는 부분이 필요한데, 이를 스케줄러scheduler라고 한다.</summary></entry><entry><title type="html">디렉토리의 구조</title><link href="http://localhost:4000/system/directory/" rel="alternate" type="text/html" title="디렉토리의 구조" /><published>2020-06-18T00:00:00+09:00</published><updated>2020-06-18T00:00:00+09:00</updated><id>http://localhost:4000/system/directory</id><content type="html" xml:base="http://localhost:4000/system/directory/">파일시스템에서 유저가 특정 파일명에서 오프셋 위치에 있는 데이터에 접근하려고 할 때 실제 디스크에 접근하기 위해 일어나는 일은 두 단계로 나뉜다.

1. 파일명으로부터 디스크에 저장되어있는 inode를 찾아서 읽는다.
2. inode와 오프셋으로부터 해당 파일에서 오프셋 위치에 있는 블럭의 디스크상의 물리 주소를 구한다.

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;/assets/img/directory/image01.png&quot; width=&quot;90%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 1. inode and inode Array
    &lt;/p&gt;
&lt;/div&gt;

여기서 inode(information node)는 실제 데이터의 포인터와 기타 정보들을 담고 있는 데이터로, 디스크에서 위와 같이 inode array의 형태로 관리된다.

이 글에서는 1번을 용이하게 만들어주는 **디렉토리**에 대해서 다루려고 한다.

&gt; 디렉토리도 일종의 파일이다.

디렉토리도 파일과 크게 다르지 않다. 디렉토리도 그 디렉토리가 포함하는 하위 파일/디렉토리 정보를 디스크에 저장하고, 그 위치를 탐색하기 위해 해당 디렉토리의 inode 또한 디스크에 저장된다.

예를 들어 `/home/minus21/workspace/app01/main.py`라는 파일에 접근하는 상황을 생각해보자. 루트 디렉토리인 `/`는 inode 인덱스가 고정되어있기 때문에 inode를 찾아낼 수 있고, 이 inode를 통해 하위 디렉토리들의 이름이 inode 인덱스로 다음과 같이 매핑된다. (이 매핑을 구현하기 위해 다양한 자료구조가 사용될 수 있다)

```
name | inode index
-----|-------------
bin  | 737
usr  | 924
home | 14
proc | 47
```

그러면 home의 inode 인덱스 14로부터 inode에 접근할 수 있고, 이 inode가 가리키는 블럭에는 또 같은 형태의 매핑이 존재한다.

```
name   | inode index
-------|-------------
minus21| 287
user01 | 894
```

이런 식으로 반복하여 최종적으로 app01 디렉토리의 inode에 접근하고, 이 inode가 가리키는 블럭에 저장된 `main.py`라는 파일의 inode를 찾아내어 위에 적은 2번 과정을 하면 된다.



## 큰 디렉토리

디스크는 블럭 단위(4KB)로 정보가 관리되는데, 디렉토리의 하위 파일/디렉토리가 아주 많아서 정보가 4KB를 넘어가면 어떻게 될까? 이 범람을 해결하기 위해서는 한 디렉토리를 여러 블럭으로 관리해야 하는데, 디렉토리를 접근하는 다음 두 상황을 모두 고려해야 한다.

* 파일명(또는 디렉토리명)으로부터 파일에 해당하는 inode를 찾는다.
* 디렉토리 내부의 파일(또는 디렉토리)들을 빠르게 순서대로 탐색할 수 있다.

즉, 쉽게 말해서 무작위 접근, 순차적 접근 모두 빨라야 한다. 그래서 디렉토리를 구현할 때 B+ 트리와 같은 형태가 사용될 수 있다.



## 출처

[1] 2020 Spring CS330 Operating System Lecture of KAIST</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="System" /><category term="file system" /><category term="directory" /><summary type="html">파일시스템에서 유저가 특정 파일명에서 오프셋 위치에 있는 데이터에 접근하려고 할 때 실제 디스크에 접근하기 위해 일어나는 일은 두 단계로 나뉜다.</summary></entry><entry><title type="html">파일 인덱싱 구조</title><link href="http://localhost:4000/system/file-indexing/" rel="alternate" type="text/html" title="파일 인덱싱 구조" /><published>2020-06-18T00:00:00+09:00</published><updated>2020-06-18T00:00:00+09:00</updated><id>http://localhost:4000/system/file-indexing</id><content type="html" xml:base="http://localhost:4000/system/file-indexing/">운영체제에서 파일시스템은 유저가 파일 이름을 통해서 디스크의 물리적 주소에 저장된 데이터에 접근하는 것을 가능하게 해준다.

1. 파일 이름은 각 디렉토리에서 접근하려는 파일의 여러가지 정보를 담고 있는 메타데이터(inode)로 변환되고
2. 메타데이터를 통해 필요한 데이터가 저장된 디스크의 블럭을 찾아내어 물리적 주소를 통해 접근한다.

이 글에서는 2번에서 어떤 indexing structure을 통해 어떤 방식으로 메타데이터에 디스크의 블럭 주소들이 저장되는지를 알아볼 것이다. 유저가 사용하는 파일과 디스크에 저장된 데이터에 대해 다음과 같은 특징이 존재한다는 것을 기억하자.

* 디스크에 있는 데이터는 블럭 단위로 관리된다.
* 한 파일이 반드시 디스크에서 연속적으로 저장된다는 보장이 없다. fragmentation을 방지하기 위해 높은 확률로 이곳저곳에 쪼개져 있을 것이다.
* 유저가 파일에 접근할 때 파일의 데이터를 연속적으로 읽기도 하고, 랜덤하게 읽기도 한다.
* 파일의 크기는 변할 수 있다.

## Linked List

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;https://media.geeksforgeeks.org/wp-content/uploads/linkedListAllocation.jpg&quot; width=&quot;40%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 1. Linked List File Allocation [1]
    &lt;/p&gt;
&lt;/div&gt;

디스크에 있는 각 블럭이 다음 블럭의 포인터를 저장하고 있다. 파일의 메타데이터는 첫 번째 블럭을 가리킨다.

**장점**

- 순차적 접근이 빠르다.
- 구현이 간단하다.
- 쉽게 블럭을 추가하고 삭제한다.

**단점**

* 무작위 접근이 느리다. (크기가 작은 파일의 경우 캐시를 통해 해결 가능하다)

메타데이터에는 파일의 첫 번째 블럭 포인터만 저장되기 때문에 임의의 n번째 블럭에 도달하기 위해서 n개의 블럭을 직접 지나야 한다. 따라서 무작위 접근을 할 때 속도가 캐시 메모리에 의존도가 높기 때문에 크기가 작은 파일들을 주로 관리할 때 적합한 파일시스템이다. 실제로 FAT 파일시스템은 파일을 linked list로 관리하는데, USB와 같은 작은 디스크에서 자주 사용된다.



## Array

각 파일의 메타데이터가 모든 블럭 주소를 적어놓은 배열을 가진다. 배열이라는 자료구조의 장점과 단점을 그대로 답습한다.

장점

* 구현이 간단하다.
* 순차적 접근, 무작위 접근 모두 빠르다.
* 쉽게 블럭을 추가하고 삭제한다.

단점

* **배열의 크기로 파일의 최대 크기가 고정된다**. 즉, 유동적인 파일 크기 변화가 불가능하다.

파일의 최대 크기를 늘리자고 배열의 크기를 모든 파일에 대해서 크게 설정할 수도 없는 노릇이다. 파일시스템으로 사용할 수 없다.



## Multi-level Indexing

배열의 단점을 보완한 방법이다. 해당 방법을 이용하는 파일 시스템으로는 Berkeley UNIX FFS가 있는데, inode에 15개의 블럭 포인터가 저장되어 있다. 이 블럭 포인터들은 디스크에 저장된 다른 블럭 포인터의 주소를 저장할 수도 있고, 바로 물리적 디스크 주소를 저장할 수도 있다.

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;https://media.geeksforgeeks.org/wp-content/uploads/Combined-Scheme.jpg&quot; width=&quot;40%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 2. Multi-level indexing [1]
    &lt;/p&gt;
&lt;/div&gt;

FFS를 기준으로, 첫 번째 12개의 포인터들은 바로 데이터가 담긴 블럭을 가리킨다. 각 블럭이 4KB일 때,  최대 48KB까지 수용할 수 있다.

13번째 포인터는 indirect 블럭 포인터인다. 이 포인터는 데이터 포인터들을 담고 있는 디스크의 블럭을 가리킨다. 즉, 가리키고 있는 블럭의 크기는 4KB이고, 물리적 주소가 32비트라고 했을 때 이는 4바이트이므로 가리키고 있는 블럭에 최대 1K개의 포인터를 수용할 수 있다. 이 1K개의 포인터는 각각 다른 4KB 짜리 데이터가 저장된 블럭을 가리키므로, 1K와 4KB를 곱해서 최대 4MB의 데이터가 수용 가능하다.

14번째 포인터는 doubly indirect 블럭 포인터이다. 이 포인터가 가리키고 있는 블럭은 1K의 indirect 블럭을 가리키는데, 각각의 indirect 블럭은 최대 4MB의 데이터가 수용 가능하므로 1K와 4MB를 곱한 4GB의 데이터가 수용 가능하다.

마지막인 15번째 포인터는 triply indirect 블럭 포인터로, 같은 방식으로 4TB의 데이터가 수용 가능하다.

이렇게 총 4KB+4MB+4GB+4TB의 데이터를 저장하고 접근할 수 있다.

장점

- 무작위 접근, 순차적 접근 모두 좋다.
- 용량의 제한이 거의 느껴지지 않는다.

단점

- 구현이 복잡하다.
- 파일에 접근할 때 디스크에서 여러 번의 indirection을 반복하면 느려진다. (캐시로 보완 가능)



## 출처

[1] [GeeksforGeeks - File Allocation Methods](https://www.geeksforgeeks.org/file-allocation-methods/)</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="System" /><category term="file system" /><summary type="html">운영체제에서 파일시스템은 유저가 파일 이름을 통해서 디스크의 물리적 주소에 저장된 데이터에 접근하는 것을 가능하게 해준다.</summary></entry><entry><title type="html">Substitution-Permuation Network</title><link href="http://localhost:4000/cryptography/SP-network/" rel="alternate" type="text/html" title="Substitution-Permuation Network" /><published>2020-06-17T00:00:00+09:00</published><updated>2020-06-17T00:00:00+09:00</updated><id>http://localhost:4000/cryptography/SP-network</id><content type="html" xml:base="http://localhost:4000/cryptography/SP-network/">DES가 대표적인 Feistel cipher 형태의 블록 암호 알고리즘이었지만 취약한 것으로 알려지면서 미국이 공모전을 통해 새로 제정한 블록 암호 알고리즘이 있는데, 바로 SP-network 형태의 AES이다. (사실 DES도 유사 SP 과정을 Feristel 암호의 round function으로 사용한다)

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;https://upload.wikimedia.org/wikipedia/commons/c/cd/SubstitutionPermutationNetwork2.png&quot; width=&quot;40%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 1. 3단계 SP Network 암호 [1]
    &lt;/p&gt;
&lt;/div&gt;



## 암호화

### S-box

S가 치환substitution의 약자인만큼, 입력 비트를 일정한 길이로 쪼개서 그 각각을 **같은 길이**의 비트로 치환시킨다. 복호화도 가능하게 하기 위해서 **one-to-one** 관계를 유지해야 한다. Figure 1에서 16비트 평문을 4비트씩 쪼개서 치환시키는 것이 이에 해당한다. S-box는 비선형성이 보장된다.



### P-box

P는 비트를 섞는 과정이다. permutation의 약자로, Figure 1에서 P 상자를 자세히 보면 세 번째 비트가 첫 번째 비트가 되고, 14번째 비트가 16번째 비트가 되는 것들을 볼 수 있을 것이다. 이는 입력 비트를 x 벡터, 출력 비트를 y 벡터로 표현했을 때 y=Ax가 되는 행렬 A가 간단하게 존재하므로 선형이다. 또한, 이 비트를 섞는 과정을 역으로 언제나 수행할 수 있고 이는 복호화해서 사용된다.



### Key

매 라운드마다 비밀 키와 XOR시킨다.



## 복호화

앞에서 서술했듯 S-box와 P-box에 역함수의 존재성이 보장되므로 암호화하는 과정을 역함수를 이용해서 거꾸로 진행하면 된다.



## 출처

[1] Wikipedia - Substitution-permutation network</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="Cryptography" /><category term="SP network" /><category term="block cipher" /><summary type="html">DES가 대표적인 Feistel cipher 형태의 블록 암호 알고리즘이었지만 취약한 것으로 알려지면서 미국이 공모전을 통해 새로 제정한 블록 암호 알고리즘이 있는데, 바로 SP-network 형태의 AES이다. (사실 DES도 유사 SP 과정을 Feristel 암호의 round function으로 사용한다)</summary></entry><entry><title type="html">Feistel Cipher</title><link href="http://localhost:4000/cryptography/Feistel-cipher/" rel="alternate" type="text/html" title="Feistel Cipher" /><published>2020-06-15T00:00:00+09:00</published><updated>2020-06-15T00:00:00+09:00</updated><id>http://localhost:4000/cryptography/Feistel-cipher</id><content type="html" xml:base="http://localhost:4000/cryptography/Feistel-cipher/">Feistel 암호는 블록 암호의 일종이다. DES가 대표적이다.

&lt;div align=&quot;center&quot;&gt;
	&lt;img src = &quot;https://upload.wikimedia.org/wikipedia/commons/f/fa/Feistel_cipher_diagram_en.svg&quot; width=&quot;40%&quot; style=&quot;background-color:white;&quot;/&gt;
    &lt;p&gt;
        Figure 1. Feistel 암호의 암호화와 복호화 [1]
    &lt;/p&gt;
&lt;/div&gt;

후술할 암호화와 복호화 과정은 위 그림 하나로 다 설명된다. 암호화할 때 $f$라는 라운드 함수를 사용하는데, 암호화할 때나 복호화할 때나 공통적으로 $f^{-1}$도 아닌 $f$를 그대로 사용한다! 즉, 어떤 형태의 $f$를 제안해도 그것으로 블록 암호를 만들 수 있다는 자유도가 있다. 그리고 암호화하는 과정과 복호화하는 과정이 닮아있기 때문에 시간도 같게 걸린다.



## 암호화

- 입력: 암호화할 $L_0 \vert\vert R_0$ 블록, 공통적으로 사용할 비밀키 $k_0, \cdots , k_{r-1} $
- 출력: r번의 라운드 함수를 거쳐서 만들어진 $L_r \vert\vert R_r $ 블록

기본적이므로 블록 암호이므로 고정된 길이의 입력 $L_0 \vert\vert R_0$을 암호화하는 과정을 살펴볼 것이다. $L_0$와 $R_0$의 길이는 같다.

r-round Feistel 암호는 이 블록을 매 단계마다 다음과 같이 암호화한다:

$$
(L_{i+1}, R_{i+1}) = (R_i, L_i \oplus f(R_i, k_i)) \quad \text{for } i=0,2,\cdots,r-1
$$

여기서 $f$를 라운드 함수round function이라고 부르고, 이 라운드 함수에 사용되는 $k_i$는 i번째 비밀 키이다.

이렇게 r개의 라운드를 거쳐서 나오는 $R_r \vert\vert L_r$이 암호화된 블록이다.



## 복호화

* 입력: 복호화할 $L_r \vert\vert R_r$ 블록, 공통적으로 사용할 비밀키  $k_0, \cdots , k_{r-1} $
* 출력: $L_0 \vert\vert R_0$ 평문 블록

암호화와 똑같은 과정을 뒤집어서 수행한다.

$$
(R_i, L_i) = (L_{i+1},R_{i+1}\oplus f(L_{i+1},k_i)) \quad \text{for } k=0,1,\cdots,r-1
$$

## 검증

r-round Feistel의 복호화 과정이 정확한 지 확인하고 싶다면, 다음을 확인하면 된다. E와 D는 각각 암호화encrypt와 복호화decrypt를 의미한다.

1. $(L_{i+1}, R_{i+1}) = E(L_i, R_i) = (R_i, L_i \oplus f(R_i, k_i))$
2. $(L_i', R_i') = D(L_{i+1}, R_{i+1})=(R_{i+1} \oplus f(L_{i+1}, k_i)), L_{i+1} )$
3. $(L_i',R_i ') = (L_i, R_i)$인가?

먼저, $R_i' = L_{i+1} = R_i$임은 쉽게 확인된다.

$$
L_i' = R_{i+1} \oplus f(L_{i+1}, k_i) = (L_i \oplus f(R_i,k_i)) \oplus f(L_{i+1}, k_i) = L_i \oplus (f(R_i, k_i) \oplus f(L_{R_i, k_i})) = L_i
$$

따라서 각 단계마다 복호화가 유효하다는 것이 확인되었고, 이 단계들로 구성된 r-round Fesistel 암호의 전체 복호화 과정도 정확하다.



## 출처

[1] Wikipedia - Feistel Cipher</content><author><name>Youngseok Choe</name><email>dev.youngseok@gmail.com</email></author><category term="Cryptography" /><category term="Feistel" /><category term="block cipher" /><summary type="html">Feistel 암호는 블록 암호의 일종이다. DES가 대표적이다.</summary></entry></feed>